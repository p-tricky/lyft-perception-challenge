{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import skvideo.io\n",
    "from models import UNet11, LinkNet34\n",
    "from torchvision import transforms\n",
    "img_transform = transforms.Compose([\n",
    "    lambda x: x[:544],\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.255])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = skvideo.io.vread('Example/test_video.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "start = time.time()\n",
    "frames = 0\n",
    "out = None\n",
    "for rgb_frame in video:\n",
    "    input_img = torch.unsqueeze(img_transform(rgb_frame).cuda(), dim=0)\n",
    "    out = model(input_img)\n",
    "    frames += 1\n",
    "end = time.time()    \n",
    "print(\"fps: {}\".format(frames/(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = glob.glob('data/Train/CameraRGB/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = np.random.choice(train, 80, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = [f.split('/')[-1] for f in val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "trainRGB = 'data/Train/CameraRGB/'\n",
    "trainSeg = 'data/Train/CameraSeg/'\n",
    "valRGB = 'data/Val/CameraRGB/'\n",
    "valSeg = 'data/Val/CameraSeg/'\n",
    "\n",
    "for f in val:\n",
    "    shutil.move(trainRGB+f, valRGB)\n",
    "    shutil.move(trainSeg+f, valSeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        lambda x: x[:544],\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        lambda x: x[:544],\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# data_dir = 'data'\n",
    "# image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "#                                           data_transforms[x])\n",
    "#                   for x in ['train', 'val']}\n",
    "# dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "#                                              shuffle=True, num_workers=4)\n",
    "#               for x in ['train', 'val']}\n",
    "# dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "# class_names = image_datasets['train'].classes\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class UDSegDataset(Dataset):\n",
    "    def __init__(self, file_names, path, transform):\n",
    "        self.rgb_file_names = [path + 'CameraRGB/' + f for f in file_names]\n",
    "        self.seg_file_names = [path + 'CameraSeg/' + f for f in file_names]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rgb_file_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        bgr_img = cv2.imread(self.rgb_file_names[idx])\n",
    "        rgb_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)\n",
    "        seg_img = cv2.imread(self.seg_file_names[idx])[:544, :, 2]\n",
    "        \n",
    "        img = self.transform(rgb_img)\n",
    "        road_mask = np.where((seg_img == 7) | (seg_img == 6), 1, 0)\n",
    "        car_mask = np.where(seg_img == 10, 2, 0)\n",
    "        car_mask[496:] = 0\n",
    "#         mask = np.dstack((road_mask, car_mask)).transpose((2, 0, 1))\n",
    "        mask = road_mask+car_mask\n",
    "        return img, torch.tensor(mask, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import gc\n",
    "from torchvision import transforms\n",
    "from dataset import UDSegDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from models import LinkNet34\n",
    "from loss import LossMulti\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training loop\n",
    "w = 800\n",
    "h = 544\n",
    "batch_sz = 8\n",
    "\n",
    "files = { x: [os.path.basename(f) for f in glob.glob(\n",
    "    'data/'+x+'/CameraRGB/*.png')] for x in {'train', 'val'}}\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        lambda x: x[:544],\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        lambda x: x[:544],\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "dataloader = {x: \n",
    "              DataLoader(\n",
    "                  UDSegDataset(files[x], 'data/'+x+'/', data_transforms[x]), \n",
    "                  batch_size=8, \n",
    "                  shuffle=True, \n",
    "              ) \n",
    "              for x in {'train','val'}}\n",
    "\n",
    "# def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "#     since = time.time()\n",
    "    \n",
    "#     best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#     best_acc = 0.0\n",
    "    \n",
    "#     for epoch in range(num_epochs):\n",
    "#         print('Epoch {}/{}'.format(epoch, num_epochs-1))\n",
    "#         print('-' * 10)\n",
    "        \n",
    "#         for phase in ['train', 'val']:\n",
    "#             if phase == 'train':\n",
    "#                 scheduler.step()\n",
    "#                 model.train()\n",
    "#             else:\n",
    "#                 model.eval()\n",
    "                \n",
    "#             running_loss = 0.0\n",
    "#             running_corrects = 0.0\n",
    "            \n",
    "#             for bi, (inputs, labels) in enumerate(dataloader[phase]):\n",
    "#                 for obj in gc.get_objects():\n",
    "#                     if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "#                         print(type(obj), obj.size())\n",
    "#                 print('starting batch {}'.format(bi))\n",
    "# #                 inputs = inputs.cuda()\n",
    "# #                 labels = labels.cuda()\n",
    "                \n",
    "#                 optimizer.zero_grad()\n",
    "                \n",
    "#                 with torch.set_grad_enabled(phase == 'train'):\n",
    "#                     outputs = model(inputs)\n",
    "#                     _, preds = torch.max(outputs, dim=1)\n",
    "#                     loss = criterion(outputs, labels)\n",
    "                    \n",
    "#                     if phase == 'train':\n",
    "#                         loss.backward()\n",
    "#                         optimizer.step()\n",
    "                        \n",
    "#                 running_loss += loss.item() * inputs.size(0)\n",
    "#                 running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "#             epoch_loss = running_loss / len(dataloader[phase])\n",
    "#             epoch_acc = running_corrects.double() / (len(dataloader[phase]) * w * h)\n",
    "            \n",
    "#             if phase == 'val' and epoch_acc > best_acc:\n",
    "#                 best_acc = epoch_acc\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "#         print()\n",
    "\n",
    "#     time_elapsed = time.time() - since\n",
    "#     print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "#         time_elapsed // 60, time_elapsed % 60))\n",
    "#     print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "#     # load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinkNet34(num_classes=3, pretrained=False).cuda()\n",
    "model.load_state_dict(torch.load('./best.pt'))\n",
    "criterion = LossMulti(jaccard_weight=1, num_classes=3, class_weights=torch.tensor([.1, .65, .25], dtype=torch.float).cuda())\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "num_epochs = 2\n",
    "road_beta, car_beta = 0.5, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 1.7962, car_re: 0.705, car_pre: 0.793, road_re: 0.996, road_pre: 0.9541, total_score: 0.8416\n",
      "val Loss: 0.7387, car_re: 0.919, car_pre: 0.873, road_re: 0.998, road_pre: 0.9842, total_score: 0.9480\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 1.6615, car_re: 0.734, car_pre: 0.794, road_re: 0.996, road_pre: 0.9567, total_score: 0.8546\n",
      "val Loss: 0.7244, car_re: 0.921, car_pre: 0.880, road_re: 0.998, road_pre: 0.9840, total_score: 0.9497\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 1.6451, car_re: 0.745, car_pre: 0.786, road_re: 0.996, road_pre: 0.9577, total_score: 0.8592\n",
      "val Loss: 0.7210, car_re: 0.919, car_pre: 0.884, road_re: 0.998, road_pre: 0.9850, total_score: 0.9495\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 1.6166, car_re: 0.749, car_pre: 0.798, road_re: 0.996, road_pre: 0.9579, total_score: 0.8617\n",
      "val Loss: 0.7298, car_re: 0.921, car_pre: 0.874, road_re: 0.998, road_pre: 0.9847, total_score: 0.9491\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 1.5924, car_re: 0.744, car_pre: 0.794, road_re: 0.996, road_pre: 0.9601, total_score: 0.8605\n",
      "val Loss: 0.7261, car_re: 0.916, car_pre: 0.882, road_re: 0.998, road_pre: 0.9847, total_score: 0.9482\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 1.5423, car_re: 0.763, car_pre: 0.795, road_re: 0.996, road_pre: 0.9608, total_score: 0.8685\n",
      "val Loss: 0.7042, car_re: 0.922, car_pre: 0.876, road_re: 0.998, road_pre: 0.9846, total_score: 0.9498\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 1.4832, car_re: 0.775, car_pre: 0.808, road_re: 0.996, road_pre: 0.9612, total_score: 0.8745\n",
      "val Loss: 0.7178, car_re: 0.915, car_pre: 0.878, road_re: 0.998, road_pre: 0.9849, total_score: 0.9473\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 1.4896, car_re: 0.773, car_pre: 0.802, road_re: 0.996, road_pre: 0.9615, total_score: 0.8736\n",
      "val Loss: 0.6377, car_re: 0.933, car_pre: 0.883, road_re: 0.998, road_pre: 0.9847, total_score: 0.9548\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 1.5443, car_re: 0.758, car_pre: 0.796, road_re: 0.996, road_pre: 0.9601, total_score: 0.8661\n",
      "val Loss: 0.6524, car_re: 0.929, car_pre: 0.885, road_re: 0.998, road_pre: 0.9847, total_score: 0.9537\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 1.4647, car_re: 0.784, car_pre: 0.800, road_re: 0.996, road_pre: 0.9609, total_score: 0.8773\n",
      "val Loss: 0.6815, car_re: 0.923, car_pre: 0.884, road_re: 0.998, road_pre: 0.9843, total_score: 0.9508\n",
      "\n",
      "Training complete in 47m 19s\n",
      "Best val Acc: 0.954809\n"
     ]
    }
   ],
   "source": [
    "# train_model(model, criterion, optimizer, exp_lr_scheduler)\n",
    "since = time.time()\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs-1))\n",
    "    print('-' * 10)\n",
    "\n",
    "    for phase in ['train', 'val']:\n",
    "#     for phase in ['val']:\n",
    "        if phase == 'train':\n",
    "            scheduler.step()\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0\n",
    "        road_prec, road_recall, car_prec, car_recall = 0,0,0,0\n",
    "        for bi, (inputs, labels) in enumerate(dataloader[phase]):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, dim=1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            road_prec += (torch.sum((preds == 1) * (labels.data == 1)).item() / \n",
    "                              torch.sum(preds == 1).item())\n",
    "            road_recall += (torch.sum((preds == 1) * (labels.data == 1)).item() / \n",
    "                              torch.sum(labels.data == 1).item())\n",
    "            \n",
    "            car_prec += (torch.sum((preds == 2) * (labels.data == 2)).item() / \n",
    "                              torch.sum(preds == 2).item())\n",
    "            car_recall += (torch.sum((preds == 2) * (labels.data == 2)).item() / \n",
    "                              torch.sum(labels.data == 2).item())\n",
    "            \n",
    "#             print(('{} Loss: {:.4f}, car_re: {:.3f}, car_pre: {:.3f}, road_re: {:.3f}, road_pre: {:.4f}')\n",
    "#                   .format(\n",
    "#                       bi+1, running_loss/(bi+1), car_recall/(bi+1), car_prec/(bi+1), \n",
    "#                       road_recall/(bi+1), road_prec/(bi+1)))\n",
    "        \n",
    "        car_prec /= len(dataloader[phase])\n",
    "        car_recall /= len(dataloader[phase])\n",
    "        road_prec /= len(dataloader[phase])\n",
    "        road_recall /= len(dataloader[phase])\n",
    "        \n",
    "        road_f1 = (1+road_beta**2) * ((road_prec*road_recall)/\n",
    "                                          (road_beta**2*road_prec+road_recall))\n",
    "        car_f1 = (1+car_beta**2) * ((car_prec*car_recall)/\n",
    "                                      (car_beta**2*car_prec+car_recall))\n",
    "        epoch_acc = (road_f1+car_f1)/2\n",
    "        \n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader[phase])\n",
    "\n",
    "        print(('{} Loss: {:.4f}, car_re: {:.3f}, car_pre: {:.3f}, road_re: {:.3f}, ' + \n",
    "              'road_pre: {:.4f}, total_score: {:.4f}').format(\n",
    "                phase, epoch_loss, car_recall, car_prec, road_recall, road_prec, epoch_acc))\n",
    "        \n",
    "        if phase == 'val' and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            #torch.save(best_model_wts, './best.pt')\n",
    "            \n",
    "\n",
    "    print()\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))\n",
    "print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "# load best model weights\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model_wts, './new_best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdl = dataloader['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, masks = None, None\n",
    "for i, m in tdl:\n",
    "    imgs, masks = i, m\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, preds = torch.max(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(preds[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(masks[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imgs[0].cpu().numpy().transpose(1, 2, 0)\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "img = std * img + mean\n",
    "img = np.clip(img, 0, 1)\n",
    "mask = masks[0].cpu().numpy()\n",
    "my_mask = outputs[0].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_mask = np.argmax(my_mask, axis=0).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_img = np.copy(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_img[(my_mask==1).nonzero()] = (0, 0, 1)\n",
    "masked_img[(my_mask==2).nonzero()] = (0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(masked_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_img = cv2.addWeighted(img, .7, masked_img, .3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(weighted_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.pad(weighted_img, ((0, 56), (0, 0), (0,0)), 'constant', constant_values=(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
